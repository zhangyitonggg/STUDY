# 深度学习基础

## 引言

![image-20250113001611381](imgs\image-20250113001611381.png)

##### **应用**

* 图像分类
* 物体检测和分割
* 样式迁移
* 人脸合成
* 文字生成图片
* 文字生成
* 无人驾驶

#### 硬件

* CPU 中央处理器
* GPU 图形处理器
* DSP 数字信号处理
* FPGA 可编程阵列
* ASIC 应特定用户的要求，或特定电子系统的需要，专门设计、制造的集成电路
  * TPU 谷歌的张量处理器
  * NPU 神经网络处理器

##### **安装**

##### **数据操作**

* 张量
* numpy

##### **数据预处理 **

##### **线性代数基础**

* 特征向量和特征值
  * 不被矩阵改变方向的向量
  * 对称矩阵总是可以找到特征向量

##### **矩阵计算**

![image-20250113154537330](imgs\image-20250113154537330.png)

## 线性神经网络

### 线性回归

* 线性回归是对n维输入的加权，外加偏移
* 使用平方损失来衡量预测值和真实值的差异
* 线性回归有显示解
* 线性回归可以看作是单层神经网络

### 基础优化方法

* 梯度下降

* 小批量随机梯度下降 

  批量大小 + 学习率

 ### Softmax回归

> 名为回归，实际是一个多类分类模型

* 使用	 Softmax 操作子得到每个类的预测置信度
* 使用交叉熵来衡量预测和标号的区别

$$
\mathrm{softmax}(\mathbf{X})_{ij} = \frac{\exp(\mathbf{X}_{ij})}{\sum_{k} \exp(\mathbf{X}_{ik})} 
$$



### 损失函数

#### L2 Loss

$$
l(y, y') = \frac{1}{2}(y-y')^2
$$

#### L1 Loss

$$
l(y, y') = |y-y'|
$$

#### Huber's Robust Lost 

$$
l(y,y') = 
\begin{cases}
|y - y'| - \frac{1}{2} & \text{if } |y - y'| > 1 \\
\frac{1}{2}(y - y')^2 & \text{otherwise}
\end{cases}
$$

## 多层感知机  

### 多层感知机

#### 感知机

**定义**

$给定输入x，权重w，和偏移b，感知机输出：$
$$
o = \sigma(\langle \mathbf{w}, \mathbf{x} \rangle + b) \quad \sigma(x) = \begin{cases}
1 & \text{if } x > 0 \\
-1 & \text{otherwise}
\end{cases}
$$

**训练**

<img src=".\imgs\image-20250119002815696.png" alt="image-20250119002815696" style="zoom:50%;" />

**总结**

* 二分类模型
* 求解算法等价于使用批量大小为1的梯度下降
* 无法拟合 XOR 函数

#### 多层感知机

* 多层感知机使用隐藏层和激活函数来得到非线性模型
* 超参数
  * 隐藏层数
  * 每层隐藏层的大小

* 必须加入非线性激活函数，否则多层感知机仍然是线性的（避免层数的塌陷）：

  * Sigmoid 激活函数    (0,1)

    $\text{sigmoid}(x)=\frac{1}{1 + \exp(-x)}$

  * Tanh 激活函数    (-1,1)

    $\tanh(x)=\frac{1 - \exp(-2x)}{1 + \exp(-2x)}$

  * **ReLU** 激活函数

    $ReLU(x) = max(x,0)$

* 多类分类多层感知机 与 Softmax 的区别是多了隐藏层

### 模型训练

#### 数据集

> 训练误差 + 泛化误差

* 训练数据集
* 验证数据集
* 测试数据集
* 小数据集上通常采用 **k-折交叉验证** 

#### 过拟合和欠拟合

* 模型容量：拟合各种函数的能力
  * 低容量的模型难以拟合训练数据
  * 高容量的模型可以记住所有训练数据

* 估计模型容量：
  * 参数的个数
  * 参数值的选择范围

#### 数据复杂度

#### 权重衰退

> 权重衰退通过 L2 正则项使得模型参数不会过大，从而控制模型复杂度

* 使用均方范数作为硬性限制
  $$
  \min \ \ell(\mathbf{w}, b) \quad \text{subject to} \quad \|\mathbf{w}\|^{2} \leq \theta
  $$

* 使用均方范数作为柔性限制
  
  对每个$\theta$，都可以找到$\lambda$使得之前的目标函数等价于下面
  $$
  \min \ \ell(\mathbf{w}, b) + \frac{\lambda}{2}\|\mathbf{w}\|^{2}
  $$

  超参数$lambda$控制了正则项的重要程度

#### 丢弃法

丢弃法：在**层之间**加入噪音 dropout

$$ x_i' =  \begin{cases} 0 & \text{with probability } p \\ \frac{x_i}{1 - p} & \text{otherwise} \end{cases} $$

这样可以确保$x'$的期望等于$x$。

* 丢弃法将一些输出项随机置0来控制复杂度
* 通常将丢弃法作用在多层感知机的隐藏层的输出上
* 丢弃概率是控制模型复杂度的超参数
* 推理时丢弃法返回输入，即$h == dropout(h)$

## 深度学习计算

### 模型构造

* 一个块可以由许多层和块组成
* 块可以包含代码
* 块负责大量的内部处理，包括参数初始化和反向传播
* 层和块的顺序连接由 Sequential 块组成 

### 参数管理

#### 参数访问

#### 初始化参数

#### 参数绑定

实际上是指不同层实际上是同一个对象

## 卷积神经网络 

### 从全连接层到卷积

**原则**

* 平移不变性
* 局部性

### 卷积层

* 卷积层将输入和核矩阵进行交叉相关，加上偏移后得到输出
* 核矩阵和偏移是可学习的参数
* 核矩阵的大小是超参数

### 填充和步幅

 填充和步幅可以用于调整数据的维度

* 填充：增加输出的高度和宽度
* 步幅：减小输出的高度和宽度 

 ### 多输入多输出通道

* 多个输入通道
* 多个输出通道
* $1\times1$卷积层：不识别空间模式，只是融合通道 $\to$ 等价于全连接 

![image-20250123015825297](imgs\image-20250123015825297.png)

* 每个输入通道有独立的二维卷积核，所有通道相加得到一个输出通道结果
* 每个输出通道有独立的三维卷积核

### 池化层

**作用**：缓解卷积层对位置的敏感性

**分类**：最大池化层 + 平均池化层

**超参数**：填充、步幅、通道（输出通道数等于输入通道输)

pytorch 中步幅与池化窗口的大小默认相同：

```python
pool2d = nn.MaxPool2d(3)
pool2d = nn.MaxPool2d(3, padding=1, stride=2)
```

### LeNet

#### 原理

![](imgs\image-20250123024937398.png)

* 先使用卷积层来学习图片空间信息
* 然后使用全连接层来转换到类别空间

## 现代卷积神经网络

- AlexNet。它是第一个在大规模视觉竞赛中击败传统计算机视觉模型的大型神经网络；
- 使用重复块的网络（VGG）。它利用许多重复的神经网络块；
- 网格中的网络（NiN）。它重复使用由卷积层和1×1卷积层（用来代替全连接层）来构建深层网络;
- 含并行连结的网络（GoogLeNet）。它使用并行连结的网络，通过不同窗口大小的卷积层和最大汇聚层来并行抽取信息；
- 残差网络（ResNet）。它通过残差块构建跨层的数据通道，是计算机视觉中最流行的体系架构；
- 稠密连接网络（DenseNet）。它的计算成本很高，但给我们带来了更好的效果。

### AlexNet

![image-20250123165517314](imgs\image-20250123165517314.png)

* 更深更大的 LeNet
* 主要改进：
  * 丢弃法
  * ReLu
  * MaxPooling
  * 数据增强

### VGG

![image-20250123173603567](imgs\image-20250123173603567.png)

提出了 VGG块 的概念

### NIN

![image-20250123175207215](imgs\image-20250123175207215.png)

* 交替使用 NiN块 和 步幅为2的最大池化层

  逐步减小高度和增大通道数

* NiN块使用卷积层加两个$1\times1$卷积层

  后者对每个像素增加了非线性性

* NiN使用全局平均池化层来代替VGG和AlexNet中的全连接层

  不容易过拟合，更少的参数个数

### GoogLeNet

**Inception块**

4个路径从不同层面抽取信息，然后在输出通道维合并

**架构**

5段（几次降低高宽），9个Inception块

![image-20250123195423367](imgs\image-20250123195423367.png)

![image-20250123195522315](imgs\image-20250123195522315.png)

**变种**

![image-20250124035307814](imgs\image-20250124035307814.png)

### 批量归一化

**思想**

出发点：学习底部的时候避免顶部层的变化

思想：批量归一化固定小批量中的均值和方差，然后学习出适合的偏移和缩放

![image-20250124041340401](imgs\image-20250124041340401.png)

**批量归一化层**

* 应用位置：
  * 全连接层和卷积层输出上，激活函数前
  * 全连接层和卷积层输入上
* 对于全连接层，作用在特征维
* 对于卷积层，作用在通道维

**为什么work**

可能是在每个小批量里加入噪音来控制模型复杂度

> 很多学科中，工程都走在了理论前面。

使用BN后可以使用更大的学习率，即加速收敛速度，但一般不改变模型精度

### ResNet

![image-20250124044911600](imgs\image-20250124044911600.png)

## 计算机视觉

### 数据增广

增加模型泛化性

* 翻转
* 切割
* 改变色调、饱和度、明亮度
* mix-up
* 等

### 微调

* 一个神经网络一般可以分成两块：
  * 特征抽取将原始像素变成容易线性分割的特征
  * 线性分类器来做分类
* 使用更强的正则化
  * 更小的学习率
  * 更少的数据迭代
* 固定一些层
  * 神经网络通常学习有层次的特征表示
    * 低层次的特征更加通用
    * 高层次的特征则更跟数据集相关
  * 可以固定底部一些层的参数，不参与更新（更强的正则）

### 目标检测和边缘框

* 物体检测识别图片里的多个物体的类别和位置
* 位置通常用边缘框表示
* COCO数据集

### 锚框

* 交并比 $IoU$

* 非极大值抑制 $NMS$

  在预测时，使用 NMS 来去掉冗余的预测

### 目标检测常用算法

#### 区域卷积神经网络

##### R-CNN

![image-20250125180221938](imgs\image-20250125180221938.png)

##### Fast R-CNN

![image-20250125180632015](imgs\image-20250125180632015.png)

* 使用CNN对图片抽取一次特征，将锚框映射到特征矩阵中去，然后使用

##### Faster R-CNN

![image-20250125180645950](imgs\image-20250125180645950.png)

* 使用一个 **区域提议网络** 来替代 启发式搜索 以获得更好的锚框

  其实就是一个粗一些的目标检测？

* two-stage

##### Mask R-CNN

![image-20250125181051380](imgs\image-20250125181051380.png)

* 如果有 像素级别的标号，使用 **FCN** 来利用这些信息
* RoI align 兴趣区域对齐层

#### 单发多框检测 SSD

![image-20250125181849010](imgs\image-20250125181849010.png)

* SSD通过单神经网络来检测模型
* 以每个像素为中心产生多个锚框
* 在多个段的输出上进行多尺度的检测
* one-stage

#### YOLO

![image-20250125184247469](imgs\image-20250125184247469.png)

#### 非锚框的目标检测算法

略

### 语义分割

![image-20250126013502954](imgs\image-20250126013502954.png)

* **定义**：语义分割将图片中的每个像素分类到对应的类别
* **实例分割** 除了语义分割外，还会区别每个类的不同实例
* **语义分割数据集**：Pascal VOC2012

### 转置卷积

转置卷积可以用来增大输入高宽

![image-20250126021317632](imgs\image-20250126021317632.png)

* 在深度学习中，转置卷积一般指反卷积（和数学上不一样）

* 卷积用做下采样，转置卷积用作上采样

* 如果卷积将输入从 (h, w) 变成了 (h', w')，同样超参数下它将 (h', w') 变成 (h, w)

* 转置卷积是一种卷积：

  ![image-20250126034858572](imgs\image-20250126034858572.png)

### 全连接卷积神经网络 FCN

![image-20250126035321919](imgs\image-20250126035321919.png)

k等价于多少类，也就是把类别信息存储在了通道之中

### 样式迁移

将样式图片中的样式迁移到内容图片上，得到合成图片

![image-20250126042637389](imgs\image-20250126042637389.png)

* 训练的东西是合成的图片

* 损失函数由内容损失、风格损失、变化损失三部分组成

## 循环神经网络

### 序列模型

* 时序模型中，当前数据跟之前观察到的数据相关

* 自回归模型使用自身过去数据来预测未来

* 马尔可夫模型假设当前只跟最近少数数据相关，以此来简化模型

* 潜变量模型使用潜变量来概括历史信息

  ![image-20250126220546785](imgs\image-20250126220546785.png)

### 文本预处理

* 读取数据集
* 将字符串拆分为 token序列
  * word
  * char
* 建立一个**词典**，将token序列映射到数字索引

### 语言模型

**定义**：给定文本序列$x_1, ..., x_T$，语言模型的目标是估计联合概率$p(x_1, ..., x_T)$

**N元语法**：

![image-20250127132941502](imgs\image-20250127132941502.png)

### RNN

循环神经网络的输出取决于当下输入和前一时间的隐变量

**定义**

![image-20250127150606658](imgs\image-20250127150606658.png)

* 更新隐藏状态：$\mathbf{h}_t = \phi(\mathbf{W}_{hh}\mathbf{h}_{t - 1} + \mathbf{W}_{hx}\mathbf{x}_{t - 1} + \mathbf{b}_h)$ 
* 输出：$\mathbf{o}_t = \phi(\mathbf{W}_{ho}\mathbf{h}_t + \mathbf{b}_o)$

**困惑度**

![image-20250127135714105](imgs\image-20250127135714105.png)

**梯度裁剪**

![image-20250127135930210](imgs\image-20250127135930210.png)

**应用**

![image-20250127140120875](imgs\image-20250127140120875.png)

### 门控循环单元 GRU

* 不是每个观察值都是同等重要
* 想只记住相关的观察需要：
  * **Update门**决定当前时刻如何结合历史记忆，更新隐藏状态
  * **Reset门**控制信息“遗忘”程度，影响当前时刻对过去记忆的依赖。
* 隐状态：
  * 候选隐状态
  * 隐状态

![image-20250128190634520](imgs\image-20250128190634520.png)

### 长短期记忆网络 LSTM

**工作流程**

* **遗忘门**决定丢弃多少前一时刻的记忆
* **输入门**决定将当前输入信息和候选记忆加入多少到候选记忆单元中
* 通过遗忘门和输入门的结合，更新**记忆单元**的内容
* **输出门**决定当前时刻的隐藏状态（即LSTM的输出）

![image-20250129182944800](imgs\image-20250129182944800.png)

### 深度循环神经网络

深度循环神经网络使用多个隐藏层来获得更多的非线性性

![image-20250130204713184](imgs\image-20250130204713184.png)

### 双向循环神经网络

* 双向RNN：
  * 一个前向RNN隐层
  * 一个后向RNN隐层
  * 合并两个隐状态得到输出
* 通常用来对序列抽取特征、填空，而不是预测未来

![image-20250130205018448](imgs\image-20250130205018448.png)

### 编码器-解码器架构

* 编码器：处理输入，将文本表示成向量
* 解码器：处理输出，将向量表示成输出

![image-20250130210449928](imgs\image-20250130210449928.png)

### 序列到序列学习 Seq2Seq

**概述**

* 编码器和解码器都是RNN，其中编码器可以是双向RNN
* 将编码器最后时间隐状态用来初始解码器隐状态来完成信息传递

**训练**

解码器使用目标句子作为输入

![image-20250130214406852](imgs\image-20250130214406852.png)

**推理**

![image-20250130214422908](imgs\image-20250130214422908.png)

**评估——BLEU**

![image-20250130214522389](imgs\image-20250130214522389.png)

### 束搜索    beam-search

* 贪心搜索：计算量最小，精度最低

* 穷举搜索：计算量最高，精度最高

* 束搜索：灵活选择束宽，在正确率和计算代价之间进行权衡

  ![image-20250131125721052](imgs\image-20250131125721052.png)

  ![image-20250131125940908](imgs\image-20250131125940908.png)

## Attention is All You Need

### 注意力机制

* 卷积、全连接、池化层都只考虑**不随意线索**
* 注意力机制显示地考虑**随意线索**
  * 查询（query）：随意线索
  * 输入：一个不随意线索（key）和一个值（value）的对
  * 通过注意力池化层来有偏向性地选择某些输入
  * $f(x)=\sum_{i}\alpha(x,x_i)y_i$，这里$\alpha(x,x_i)$是注意力权重

### 注意力分数

#### 概述

注意力分数是query和key的相似度，注意力权重是分数的softmax结果

![image-20250131144204808](imgs\image-20250131144204808.png)

![image-20250131144949652](imgs\image-20250131144949652.png)

#### 两种常见的分数计算方法

**Additive Attention**

* ![image-20250131150413098](imgs\image-20250131150413098.png)

* 等价于将key和query合并起来放入一个隐藏大小为h、输出大小为1的单隐藏层MLP

**Scaled Dot-Product Attention**

![image-20250131151300432](imgs\image-20250131151300432.png)

* 直接将query和key做内积

 ### 使用注意力机制的seq2seq

* 注意力机制可以根据解码器RNN的输出来匹配到合适的编码器RNN的输出来更有效地传递信息

* 将上一时间步的解码器隐状态视为query，在所有时间步的隐状态视为key + value

![image-20250131231139058](imgs\image-20250131231139058.png)

### 自注意力和位置编码

**自注意力**

自注意力池化层将$x_i$当做key、value、query来对序列抽取特征

![image-20250201002514280](imgs\image-20250201002514280.png)

**位置编码**

![image-20250201002544117](imgs\image-20250201002544117.png)

* 绝对位置
* 相对位置

### 多头注意力机制

![image-20250131234143006](imgs\image-20250131234143006.png)

* 每个注意力图的计算方法：
  $$
  \mathbf{h}_i = f(\mathbf{W}_i^{(q)}\mathbf{q}, \mathbf{W}_i^{(k)}\mathbf{k}, \mathbf{W}_i^{(v)}\mathbf{v}) \in \mathbb{R}^{p_v}
  $$
  其中，可学习的参数包括$\mathbf{W}_i^{(q)} \in \mathbb{R}^{p_q \times d_q}$、$\mathbf{W}_i^{(k)} \in \mathbb{R}^{p_k \times d_k}$和$\mathbf{W}_i^{(v)} \in \mathbb{R}^{p_v \times d_v}$，以及代表注意力汇聚的函数$f$。$f$可以是加性注意力和缩放点积注意力。
  
* 输出是$h$个头连结后的结果，因此其可学习参数是$\mathbf{W}_o \in \mathbb{R}^{p_o \times hp_v}$：
  $$
  \mathbf{W}_o 
  \begin{bmatrix}
  \mathbf{h}_1 \\
  \vdots \\
  \mathbf{h}_h
  \end{bmatrix}
  \in \mathbb{R}^{p_o}
  $$

* 有掩码的多头注意力：
  * 解码器对序列中一个元素输出时，不应该考虑该元素之后的元素
  * 可以通过掩码实现，即计算$x_i$输出时，假设当前序列长度为$i$

### Transformer

纯使用注意力的编码-解码器

![image-20250201004623859](imgs\image-20250201004623859.png)

**基于位置的前馈网络**

* 输入：由(b,n,d)变换成(bn,d)
* 输出：由(bn,d)变换回(b,n,d)
* 作用两个全连接层
* 等价于两层核窗口为1的一维卷积层

**层归一化**

layer是对每个句子的全部字归一，batch是全部句子的第d个字归一

<img src=".\imgs\image-20250201225724770.png" alt="image-20250201225724770" style="zoom:25%;" />

**预测**

* 假设预测第$t+1$个输出：解码器中输入前$t$个预测值，在自注意力中，前$t$个预测值作为$key$和$value$，第$t$个预测值还单独作为$query$

### BERT

💡 **BERT = "双向理解 + 基于微调的NLP模型 + Transformer"** 🚀

#### **动机**

* 预训练的模型抽取足够多的信息
* 新的任务只需要增加一个简单的输出层

#### **架构**

* 只有编码器的Transformer
* 两个版本：Base + Large

#### **对输入的修改**

* 每个样本是一个句子对，句子间以$<sep>$间隔
* 位置编码可学习

#### **预训练任务**

1. 完型填空

   * 带掩码的语言模型

   * Transformer的编码器是双向的
   * 带掩码的语言模型每次随机将一些次词元换成$<mask>$

2. 下一句子预测

   * 预测一个句子对中两个句子是不是相邻的

#### 微调

**概论**

* BERT对每一个词元返回抽取了上下文信息的特征向量
* 根据任务的不同，输入的表示不同   和使用的BERT特征也会不一样

**应用例子**

* **句子分类**

  将$<cls>$对应的向量输入到全连接层分类

* **命名实体识别：**识别一个词元是不是命名实体，例如人名、机构等

  将**非特殊词元**放进全连接层分类

* **问题回答：**给定一个问题和描述文字，找出一个片段作为回答

  对片段中的每个词元预测它是不是回答的开头或结束

## 优化算法

### 优化问题

![image-20250202015840284](imgs\image-20250202015840284.png)

### 凸和非凸

![image-20250202020010414](imgs\image-20250202020010414.png)

### 小批量随机梯度下降

![image-20250202020220702](imgs\image-20250202020220702.png)

batch_size取整个训练集大小时，批量随机梯度下降就变成了梯度下降

### 冲量法

冲量对梯度做平滑

![image-20250202020440414](imgs\image-20250202020440414.png)

### Adam

对学习率很不敏感，对梯度做平滑，且对梯度各个维度值做重新调整

![image-20250202021228162](imgs\image-20250202021228162.png)